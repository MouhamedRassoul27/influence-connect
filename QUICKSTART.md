# üöÄ Influence Connect - Guide de D√©marrage Rapide

## Pr√©requis
- Docker Desktop install√© et d√©marr√©
- Port 8000 et 5432 disponibles

## 1. D√©marrer l'application

```bash
cd /tmp/influence-connect

# D√©marrer tous les services
docker compose -f docker-compose.simple.yml up -d

# Attendre 10 secondes que tout d√©marre
sleep 10

# V√©rifier que l'API fonctionne
curl http://localhost:8000/api/health
```

## 2. Seed la base de donn√©es

```bash
# Cr√©er les donn√©es de test (influenceurs, threads, messages)
docker compose -f docker-compose.simple.yml exec api python /app/scripts/seed_db.py

# G√©n√©rer les embeddings pour la knowledge base (optionnel, n√©cessite connexion Internet)
docker compose -f docker-compose.simple.yml exec api python /app/scripts/ingest_knowledge.py
```

## 3. Tester l'API

### Health check
```bash
curl http://localhost:8000/api/health
```

### Documentation interactive (Swagger)
```
http://localhost:8000/docs
```

### Lister les threads
```bash
curl http://localhost:8000/api/messages/inbox
```

### Traiter un message (pipeline IA complet)
```bash
curl -X POST http://localhost:8000/api/messages/process \
  -H "Content-Type: application/json" \
  -d '{
    "content": "Quelle cr√®me anti-rides pour peau s√®che ?",
    "platform": "instagram",
    "sender_id": "test_user_123",
    "sender_username": "test_user"
  }'
```

**üì± Pour connecter √† Instagram r√©el**: Voir [INSTAGRAM_SETUP.md](INSTAGRAM_SETUP.md)

## 4. Voir les logs

```bash
# Tous les services
docker compose -f docker-compose.simple.yml logs -f

# API seulement
docker compose -f docker-compose.simple.yml logs -f api

# Derni√®res 50 lignes
docker compose -f docker-compose.simple.yml logs --tail=50 api
```

## 5. Arr√™ter l'application

```bash
# Arr√™ter les services (garde les donn√©es)
docker compose -f docker-compose.simple.yml down

# Arr√™ter ET supprimer les donn√©es
docker compose -f docker-compose.simple.yml down -v
```

## üéØ URLs importantes

- **API Health**: http://localhost:8000/api/health
- **API Docs (Swagger)**: http://localhost:8000/docs
- **API ReDoc**: http://localhost:8000/redoc
- **Database**: localhost:5432 (user: influence, password: influence123)
- **Redis**: localhost:6379

## ‚öôÔ∏è Configuration

Modifier `.env` pour personnaliser :
```env
ANTHROPIC_API_KEY=sk-ant-votre-cl√©  # REQUIS pour l'IA
HITL_REQUIRED=true                   # Validation humaine obligatoire
LOG_LEVEL=INFO                       # DEBUG pour plus de logs
```

## üîß Troubleshooting

### Port 8000 d√©j√† utilis√©
```bash
lsof -ti:8000 | xargs kill -9
```

### Reconstruire les images
```bash
docker compose -f docker-compose.simple.yml build --no-cache
docker compose -f docker-compose.simple.yml up -d
```

### R√©initialiser compl√®tement
```bash
docker compose -f docker-compose.simple.yml down -v
docker system prune -a
docker compose -f docker-compose.simple.yml up -d --build
```

### V√©rifier les conteneurs
```bash
docker compose -f docker-compose.simple.yml ps
```

## üìù Notes

- Le mod√®le d'embedding (BAAI/bge-m3) se t√©l√©charge au premier appel RAG (~2GB)
- Sans connexion Internet, le RAG ne fonctionnera pas mais le reste de l'API oui
- Les cl√©s Anthropic de test sont requises pour les appels IA r√©els
